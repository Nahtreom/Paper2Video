# é¡µ 11
Evaluating coding tasks with test cases. For coding tasks, where ground-truth labels are often unavailable, MASLab similarly promotes LLM-assisted evaluation. Since tools like xVerify are inapplicable in this setting, we employ a two-step approach: (1) an LLM extracts executable code from the MAS output given the original query, and (2) the extracted code is executed against the provided set of test cases to determine correctness. This process ensures that evaluation focuses on functional validity and abstracts away from inconsistencies in format or verbosity. All executions are sandboxed [52] to guarantee safety and consistency.