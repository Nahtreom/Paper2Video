大语言模型的上下文长度通常有限，很难完整保存所有对话历史，我们的解决办法是按照对话阶段对记忆进行分段。一种是短期记忆，负责在单个阶段内保持对话的连续性；另一种是长期记忆，用来跨阶段保持整体的上下文感知。