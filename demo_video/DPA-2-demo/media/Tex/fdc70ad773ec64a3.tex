\documentclass[preview]{standalone}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\begin{document}
\begin{center}
DPA-2 zero-shot generalization: \\
            $\bullet$ Evaluated on downstream datasets without fine-tuning \\
            $\bullet$ Multi-task DPA-2 outperforms single-task and MACE-MP-0 \\
            $\Rightarrow$ Gains mainly due to multi-task pretraining, not just architecture
\end{center}
\end{document}