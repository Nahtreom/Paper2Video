from manim import *

class ModelDistillationEvaluation(Scene):
    def construct(self):
        # Title
        title = Text("Model Distillation and Evaluation", font_size=36, color=WHITE)
        self.play(Write(title))
        self.wait(1)
        self.play(title.animate.to_edge(UP))

        # Page 1: Motivation
        para1 = Text(
            "Fine-tuned DPA-2 achieves high accuracy but suffers from high computational cost\n"
            "due to its large parameter count.",
            font_size=24,
            line_spacing=1.2,
            color=WHITE
        ).to_edge(ORIGIN)
        self.play(Write(para1))
        self.wait(3)
        self.play(FadeOut(para1))

        # Page 2: Knowledge Distillation Overview
        para2 = Text(
            "We apply knowledge distillation:\n"
            "• Teacher: fine-tuned DPA-2 models\n"
            "• Student: compressed DPA-1 models without attention\n"
            "Training data for distillation is generated by the teacher on small downstream subsets.",
            font_size=24,
            line_spacing=1.2,
            color=WHITE
        ).to_edge(ORIGIN)
        self.play(Write(para2))
        self.wait(4)
        self.play(FadeOut(para2))

        # Page 3: Sample Efficiency (Fig. 3)
        image = ImageMobject("images/de8f6facb495c941a735b720341ac07e185f3037d55b55840263be02a46d910e.jpg")
        image.scale(0.6).next_to(title, DOWN, buff=0.5)
        caption = Text("Comparative analysis of sample efficiency on downstream tasks", font_size=20, color=WHITE)
        caption.next_to(image, DOWN, buff=0.3)
        self.play(FadeIn(image), Write(caption))
        self.wait(4)
        self.play(FadeOut(image), FadeOut(caption))

        # Page 4: Efficiency Gains
        para3 = Text(
            "After distillation, inference speed and maximum feasible system size\n"
            "improve by nearly two orders of magnitude on a single GPU,\n"
            "while accuracy remains on par with fine-tuned DPA-2.",
            font_size=24,
            line_spacing=1.2,
            color=WHITE
        ).to_edge(ORIGIN)
        self.play(Write(para3))
        self.wait(4)
        self.play(FadeOut(para3))

        # Page 5: Physical Property Tests
        para4 = Text(
            "We further validate the distilled model on three tasks:\n"
            "1. H2O-PBE0TS-MD: RDF and ADF match AIMD reference almost perfectly\n"
            "2. SSE-PBE-D: Li diffusion constants agree with DP-PBE and DFT results\n"
            "3. FerroEle-D: Temperature-driven phase transitions\n"
            "   (T-C at ~250K and ~300K) correctly reproduced",
            font_size=24,
            line_spacing=1.2,
            color=WHITE
        ).to_edge(ORIGIN)
        self.play(Write(para4))
        self.wait(5)
        self.play(FadeOut(para4))

        # Page 6: Conclusion
        conclusion = Text(
            "Knowledge distillation produces lightweight models that retain\n"
            "high accuracy and deliver massive efficiency improvements,\n"
            "making them suitable for large-scale molecular simulations.",
            font_size=24,
            line_spacing=1.2,
            color=WHITE
        ).to_edge(ORIGIN)
        self.play(Write(conclusion))
        self.wait(4)
        self.play(FadeOut(conclusion), FadeOut(title))
